{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup notebook, imports and predefined functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nhpylm.lexicon import build_fst_for_lexicon\n",
    "from nhpylm import fst\n",
    "import os\n",
    "from nhpylm.c_core import nhpylm\n",
    "from tqdm import tqdm\n",
    "from nhpylm.kaldi_data_preparation import convert_transcription, word_to_grapheme\n",
    "import json\n",
    "from nhpylm import json_utils as ju\n",
    "from copy import deepcopy\n",
    "from nhpylm.kaldi import get_kaldi_env\n",
    "from nhpylm.process_caller import run_processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_directory = 'lattice_playground/wcl-l-e-p-m/'\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some predefined functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined write and print/display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_and_print_fst(fst_graph, fst_filename, sym_filename, **kwargs):\n",
    "    print_fst_kwargs = {'determinize': False}\n",
    "    print_fst_kwargs.update(kwargs)\n",
    "    fst_graph.write_fst(fst_filename, **print_fst_kwargs)\n",
    "    return fst.print(fst_filename, sym_filename, sym_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert a list of sentences to a list of list of list of units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_splitted_words(text):\n",
    "    return [convert_transcription(line, word_to_units=word_to_grapheme(join=False))[1] for line in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return all unique units from the converted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_symbols(text):\n",
    "    return {symbol for line in text for word in line for symbol in word}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a symbol list to a symbol file mapping all symbols to integers from 1 to N_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_symbols(symbols, sym_file):\n",
    "    with open(sym_file, 'w') as fid:\n",
    "        for i, s in enumerate(symbols):\n",
    "            fid.write('{} {}\\n'.format(s, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper to run fst command easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cmd(cmds, inputs=None, env=get_kaldi_env()):\n",
    "    run_processes(cmds, inputs, environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Simulation purpose: Generate a monophone structure given a hmm prototype\n",
    "- Creates and adds the hmm input symbols to the end of the word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_monophones(hmm_prob_proto, int_labels, emitions_per_state, word_list):\n",
    "    hmm_states = hmm_prob_proto.keys()\n",
    "    emit_symb = len(word_list)\n",
    "    monophones = dict()\n",
    "    for label in int_labels:\n",
    "        monophones[label] = dict()\n",
    "        hmm = deepcopy(hmm_prob_proto)\n",
    "        for hmm_state in hmm_states:\n",
    "            if hmm_state >= 0:\n",
    "                emitions_state = list()\n",
    "                for emition in range(emitions_per_state):\n",
    "                    emitions_state.append((emit_symb, 1/num_emitions_per_state))\n",
    "                    emit_symb += 1\n",
    "                    word_list.append('{}-{}-{}'.format(word_list[label], hmm_state, emition))\n",
    "                hmm[hmm_state]['observations'] = tuple(emitions_state)\n",
    "        monophones[label] = hmm\n",
    "    return monophones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get train data, split into characters and get symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = ['Martian Marsman', 'man on Mars']\n",
    "train_data_splitted = text_to_splitted_words(train_data)\n",
    "symbols = find_symbols(train_data_splitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate LM, add training sentences and resample hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "lm = nhpylm.NHPYLM_wrapper(list(symbols), 2, 8)\n",
    "\n",
    "train_data_ids = lm.word_lists_to_id_lists(train_data_splitted)\n",
    "for line in tqdm(train_data_ids):\n",
    "    lm.add_id_sentence_to_lm(line)\n",
    "    \n",
    "lm.resample_hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get int versions of lexicon and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int_lexicon = lm.get_word_id_to_char_id()\n",
    "int_eos_word = lm.sentence_boundary_id\n",
    "int_labels = lm.get_char_ids()\n",
    "int_eps = lm.sym2id('EPS')\n",
    "int_eow = lm.sym2id('EOW')\n",
    "int_eoc = lm.sym2id('EOC')\n",
    "int_phi = lm.sym2id('PHI')\n",
    "int_eos_label = lm.sym2id('EOS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = lm.string_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build discrete HMM for characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some parameters and model prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_emitions_per_state = 2\n",
    "hmm_prob_proto = { -1: {'transitions': ((0, 1),)}, 0: {'transitions': ((0, 2/3), (1, 1/3))},\n",
    "                    1: {'transitions': ((1, 2/3), (2, 1/3))}, 2: {'transitions': ((2, 2/3), (-1, 1/3))}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build hmm and extend word list by hmm input symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monophones = get_monophones(hmm_prob_proto, int_labels, num_emitions_per_state, word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write symbol file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sym_filename = output_directory + 'symbols.txt'\n",
    "\n",
    "write_symbols(word_list, sym_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write and print monophone transducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/H.fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/H.fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb330222940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_fst_filename = output_directory + 'H.fst'\n",
    "fst_monophones = fst.build_monophone_fst(monophones, int_eps)\n",
    "fst_monophones.add_self_loops(int_eps, int_eos_label, int_eos_label)\n",
    "fst_monophones.add_self_loops(int_eps, int_eow, int_eow)\n",
    "fst_monophones.add_self_loops(int_eps, int_eoc, int_eoc)\n",
    "\n",
    "write_and_print_fst(fst_monophones, H_fst_filename, sym_filename, minimize=False, determinize=False, sort_type='olabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and print FST for lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/L.fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/L.fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb32000f8d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_fst_filename = output_directory + 'L.fst'\n",
    "mode = 'trie'\n",
    "build_character_model = True\n",
    "fst_lexicon = build_fst_for_lexicon(int_lexicon, int_eps, int_eow, build_character_model,\n",
    "                                    mode, int_labels, eoc=int_eoc)\n",
    "fst_lexicon.add_eos(int_eos_label, int_eos_word)\n",
    "write_and_print_fst(fst_lexicon, L_fst_filename, sym_filename, minimize=False, determinize=False, sort_type='ilabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get FST for language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/G.fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/G.fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb32000fb38>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_fst_filename = output_directory + 'G.fst'\n",
    "_, arc_list = lm.to_fst_text_format(eow=int_eoc)\n",
    "G_fst = fst.build_fst_from_arc_list(arc_list)\n",
    "G_fst.write_fst(G_fst_filename, minimize=False, determinize=False, rmepsilon=False)\n",
    "fst.print(G_fst_filename, sym_filename, sym_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some character sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "character_sequence = 'MartianMarsman'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and print FST for character sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/I.fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/I.fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb32000f7f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_sequence = [lm.sym2id(character) for character in character_sequence]\n",
    "\n",
    "I_fst_filename = output_directory + 'I.fst'\n",
    "character_sequence_fst = fst.build_fst_for_sequence(int_sequence + [int_eos_label])\n",
    "write_and_print_fst(character_sequence_fst, I_fst_filename, sym_filename, minimize=False, determinize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose monophone transducer with character sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/H_I.fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/H_I.fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb32000fa90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_I_fst_filename = output_directory + 'H_I.fst'\n",
    "fst.compose(H_fst_filename, I_fst_filename, H_I_fst_filename,\n",
    "            determinize=False, minimize=False, rmepsilon=False, sort_type='olabel')\n",
    "fst.print(H_I_fst_filename, sym_filename, sym_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly generate observed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/O_fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/O_fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb32000f748>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_fst_filename = output_directory + 'O_fst'\n",
    "fst.randgen(H_I_fst_filename, O_fst_filename, project=True, project_output=False, rmepsilon=True)\n",
    "fst.print(O_fst_filename, sym_filename, sym_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add loops for word end/disambigutity symbols (eow and eoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/O_loop.fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/O_loop.fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb32000f780>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_loop_fst_filename = output_directory + 'O_loop.fst'\n",
    "run_cmd(fst.fstaddselfloops_cmd(O_fst_filename, O_loop_fst_filename, [int_eow, int_eoc], [int_eow, int_eoc]))\n",
    "fst.print(O_loop_fst_filename, sym_filename, sym_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the final compositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose monophone transducer with lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/H_L.fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/H_L.fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb32000f080>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_L_fst_filename = output_directory + 'H_L.fst'\n",
    "fst.compose(H_fst_filename, L_fst_filename, H_L_fst_filename,\n",
    "            determinize=False, minimize=False, rmepsilon=False, sort_type='olabel')\n",
    "fst.print(H_L_fst_filename, sym_filename, sym_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose monophone transducer and lexicon with input sequence FST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/O_loop_H_L.fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/O_loop_H_L.fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb32000f828>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_loop_H_L_fst_filename = output_directory + 'O_loop_H_L.fst'\n",
    "fst.compose(O_loop_fst_filename, H_L_fst_filename, O_loop_H_L_fst_filename,\n",
    "            determinize=False, minimize=False, rmepsilon=False, sort_type=\"olabel\")\n",
    "fst.print(O_loop_H_L_fst_filename, sym_filename, sym_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose monophone transducer and lexicon and input sequence FST with language model FST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/O_loop_H_L_G.fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/O_loop_H_L_G.fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb32000fcf8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_loop_H_L_G_fst_filename = output_directory + 'O_loop_H_L_G.fst'\n",
    "fst.compose(O_loop_H_L_fst_filename, G_fst_filename, O_loop_H_L_G_fst_filename,\n",
    "            determinize=False, minimize=False, rmepsilon=False, phi=int_phi)\n",
    "fst.print(O_loop_H_L_G_fst_filename, sym_filename, sym_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get shortest path(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"lattice_playground/wcl-l-e-p-m/O_loop_H_L_G_shortestpath.fst.pdf\" width=1000 height=400></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{lattice_playground/wcl-l-e-p-m/O_loop_H_L_G_shortestpath.fst.pdf}"
      ],
      "text/plain": [
       "<nhpylm.display_pdf.PDF at 0x7fb3361bdb00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_loop_H_L_G_shortestpath_fst_filename = output_directory + 'O_loop_H_L_G_shortestpath.fst'\n",
    "fst.shortestpath(O_loop_H_L_G_fst_filename, O_loop_H_L_G_shortestpath_fst_filename, nshortest=1,\n",
    "            determinize=False, minimize=False, rmepsilon=True, project=True, project_output=True)\n",
    "fst.print(O_loop_H_L_G_shortestpath_fst_filename, sym_filename, sym_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
